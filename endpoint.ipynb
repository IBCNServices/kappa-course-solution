{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ingesting pageview data\n",
    "\n",
    "In this exercise, you create an HTTP endpoint that ingests page view data (clicks) into the platform. Every time a user clicks on a link and when the user scrolls to certain positions on the page, a json \"click\" objects gets sent to this endpoint.\n",
    "\n",
    "This is what a click event looks like.\n",
    "\n",
    "```json\n",
    "{\n",
    "    \"visitor_platform\": \"mobile\",\n",
    "    #\n",
    "    # Timestamp of the event (milliseconds since unix epoch)\n",
    "    \"ts_ingest\": 1515819844345,\n",
    "    \n",
    "    \"article_title\": \"Cercanías San Sebastián\",\n",
    "    \"visitor_country\": \"BE\",\n",
    "    \n",
    "    # Seconds the page was open before this event was sent.\n",
    "    # (0 when this event is sent immediately after the page was opened.)\n",
    "    \"visitor_page_timer\": 0,\n",
    "\n",
    "    \"visitor_os\": \"ios\",\n",
    "    \"article\": \"https://en.wikipedia.org/wiki/Cercan%C3%ADas_San_Sebasti%C3%A1n\",\n",
    "    \n",
    "    # How much the user scrolled before this event was sent.\n",
    "    # (0 when this event is sent while the user hasn't scrolled yet.)\n",
    "    \"visitor_page_height\": 0,\n",
    "    \n",
    "    \"visitor_browser\": \"unknown\"\n",
    "}\n",
    "```\n",
    "\n",
    "\n",
    "We use the [Python Flask framework](http://flask.pocoo.org/) to create the ingest HTTP endpoint. Flask is a lightweight and simple, but very powerful framework to write HTTP webservers in Python. Flask powers the api's of many large web services such as [Netflix](https://medium.com/netflix-techblog/python-at-netflix-bba45dae649e), [Airbnb](https://medium.com/airbnb-engineering/airflow-a-workflow-management-platform-46318b977fd8), [Uber](https://github.com/uber/clay) and [Reddit](https://stackshare.io/reddit/reddit).\n",
    "\n",
    "## Apache Kafka as event store\n",
    "\n",
    "The clicks that our API recieves are stored in [Apache Kafka](https://kafka.apache.org/), a distributed streaming platform initially created by LinkedIn. Kafka stores large distributed queues, called *topics* and allows *producers* to send data to the queue and *consumers* to read data from the queue, all in a fault-tolerant and durable way.\n",
    "\n",
    "The sole responsibility of the Ingest API is to recieve click events from HTTP POST requests and put them on the `clicks` topic in Kafka. The Ingest API itself doesn't do any cleaning or filtering, this happens later in the pipeline. Using Kafka here has a number of advantages.\n",
    "\n",
    "* Kafka acts as a **buffer** between the ingest of events and the processing events. Downstream issues, such as the processing code crashing, don't affect the ingest of events. This also allows the platform to **gracefully handle spikes in load**. When the processing code can't handle the load, Kafka will gather a backlog of unprocessed events, but the events will not be lost and the processing code can catch up when the load decreases again.\n",
    "* Kafka allows multiple consumers to subscribe to the same topic. This makes it easy to have **multiple paralell processing pipelines** which recieve the same event stream. You can use this to run multiple versions of your code next to each other in order to do tests or quality assurance. Or to have a staging environment that recieves the same event stream as the production environment.\n",
    "* Kafka is a **language-agnostic** platform with many client libraries so you can use it to create heterogenous streaming analytics pipelines.\n",
    "\n",
    "For long-term storage of the event log, you can couple Kafka with Hadoop and create a small service that persists the event log in HDFS. You can then replay the historic log using a producer that reads from HDFS, or you can process the event log in batch using a technology like Hadoop MapReduce or Spark.\n",
    "\n",
    "So, to start the exercise, let's install the required dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting kafka-python\n",
      "  Downloading https://files.pythonhosted.org/packages/82/39/aebe3ad518513bbb2260dd84ac21e5c30af860cc4c95b32acbd64b9d9d0d/kafka_python-1.4.6-py2.py3-none-any.whl (259kB)\n",
      "Collecting flask\n",
      "  Downloading https://files.pythonhosted.org/packages/9a/74/670ae9737d14114753b8c8fdf2e8bd212a05d3b361ab15b44937dfd40985/Flask-1.0.3-py2.py3-none-any.whl (92kB)\n",
      "Collecting itsdangerous>=0.24 (from flask)\n",
      "  Downloading https://files.pythonhosted.org/packages/76/ae/44b03b253d6fade317f32c24d100b3b35c2239807046a4c953c7b89fa49e/itsdangerous-1.1.0-py2.py3-none-any.whl\n",
      "Collecting Werkzeug>=0.14 (from flask)\n",
      "  Downloading https://files.pythonhosted.org/packages/9f/57/92a497e38161ce40606c27a86759c6b92dd34fcdb33f64171ec559257c02/Werkzeug-0.15.4-py2.py3-none-any.whl (327kB)\n",
      "Requirement already satisfied: Jinja2>=2.10 in /opt/conda/lib/python3.7/site-packages (from flask) (2.10.1)\n",
      "Requirement already satisfied: click>=5.1 in /opt/conda/lib/python3.7/site-packages (from flask) (7.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /opt/conda/lib/python3.7/site-packages (from Jinja2>=2.10->flask) (1.1.1)\n",
      "Installing collected packages: kafka-python, itsdangerous, Werkzeug, flask\n",
      "Successfully installed Werkzeug-0.15.4 flask-1.0.3 itsdangerous-1.1.0 kafka-python-1.4.6\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "# Install the required Python 3 dependencies\n",
    "python3 -m pip install kafka-python flask\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flask introduction\n",
    "\n",
    "The following code snippet is everything you need to get a working \"Hello World\" HTTP api. You start the server by running the cell. (select the cell with the python code and press `ctrl`-`enter`).\n",
    "\n",
    "You can test the server using the `curl` command in a terminal.\n",
    "\n",
    "```txt\n",
    "$ curl http://localhost:5000\n",
    "Index Page\n",
    "$ curl http://localhost:5000/hello\n",
    "Hello, World\n",
    "```\n",
    "\n",
    "You stop the server by clicking on the \"stop\" button on the toolbar of this notebook.\n",
    "\n",
    "![image.png](attachment:image.png)\n",
    "\n",
    "*Note: look at the appendices at the bottom of the [introduction notebook](introduction.ipynb) for more info on how to use autocompletion and show documentation in Jupyter and how to reset your environment.*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app \"__main__\" (lazy loading)\n",
      " * Environment: production\n",
      "   WARNING: This is a development server. Do not use it in a production deployment.\n",
      "   Use a production WSGI server instead.\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on http://0.0.0.0:5000/ (Press CTRL+C to quit)\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route('/')\n",
    "def index():\n",
    "    return 'Index Page\\n'\n",
    "\n",
    "@app.route('/hello')\n",
    "def hello():\n",
    "    app.route()\n",
    "    return 'Hello, World\\n'\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app.run(host='0.0.0.0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic functionality\n",
    "\n",
    "* The ` @app.route(\"/\")` annotation is used to define the URL that executes a function. In the previous example, any call to `localhost:5000/` will run the `index` function.\n",
    "* You can use the variable `request` inside of such a function to get information about the request. For example, `request.json` is a dictionary generated from the `json` body of the request.\n",
    "\n",
    "Take a look at the [Flask docs](http://flask.pocoo.org/docs/1.0/quickstart/#routing) for more information.\n",
    "\n",
    "\n",
    "# Kafka Python\n",
    "\n",
    "Below is an example for how to publish data to kafka using Python.\n",
    "\n",
    "Take a look at the [`python-kafka` docs ](https://kafka-python.readthedocs.io/en/master/usage.html) for more information.\n",
    "\n",
    "Note: if you encounter a `NoBrokersAvailable` error message, that means that the Kafka server is not reachable. Make sure that the `kafka` container is running as explained in `README,md`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test-topic:0:0: key=None value=b'Hello World!'\n",
      "test-topic:0:1: key=None value=b'Hello World!'\n",
      "test-topic:0:2: key=None value=b'Hello World!'\n",
      "test-topic:0:3: key=None value=b'Foo'\n",
      "test-topic:0:4: key=None value=b'Bar'\n"
     ]
    }
   ],
   "source": [
    "from kafka import KafkaProducer, KafkaConsumer, TopicPartition\n",
    "\n",
    "topic =\"test-topic\"\n",
    "\n",
    "producer = KafkaProducer(\n",
    "    bootstrap_servers=['localhost:9092'])\n",
    "\n",
    "# Note: The data you send must be binary\n",
    "producer.send(topic, b\"Hello World!\").get(timeout=30)\n",
    "# Note: The data you send must be binary\n",
    "producer.send(topic, b\"Foo\").get(timeout=30)\n",
    "producer.send(topic, b\"Bar\").get(timeout=30)\n",
    "\n",
    "\n",
    "# To consume latest messages and auto-commit offsets\n",
    "consumer = KafkaConsumer(\n",
    "    group_id='test-group',\n",
    "    bootstrap_servers=['localhost:9092'],\n",
    "    auto_offset_reset='earliest',\n",
    "    consumer_timeout_ms=500) # Stop iteration if no message after 5sec\n",
    "tp = TopicPartition(topic,0)\n",
    "consumer.assign([tp])\n",
    "\n",
    "consumer.seek(tp, 0)         # Go to the beginning of the queue\n",
    "\n",
    "\n",
    "for message in consumer:\n",
    "    # message value and key are raw bytes -- decode if necessary!\n",
    "    # e.g., for unicode: `message.value.decode('utf-8')`\n",
    "    print (\"%s:%d:%d: key=%s value=%s\" % (message.topic, message.partition,\n",
    "                                          message.offset, message.key,\n",
    "                                          message.value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clearing Jupyter Notebook Output\n",
    "\n",
    "> **Warning:** Since the server writes a log line to output for every request, it's possible to write so much output that the notebook hangs. Therefore, it's best to clear the output every few messages.\n",
    "\n",
    "You can clear the output using Python. It's advised to clear the output at least every 500 messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This line will be visible.\n",
      "This is visible too!\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "print(\"This line will be cleared.\")\n",
    "print(\"This line will be cleared too.\")\n",
    "clear_output()\n",
    "print(\"This line will be visible.\")\n",
    "print(\"This is visible too!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Endpoint API\n",
    "\n",
    "> **Task:** Write a server that listens for `POST` requests to the url `/clicks`, reads the body of the request as `json`, and sends sends that body to the `clicks` topic on Kafka.\n",
    "\n",
    "Use the [fake-website](fake-website.ipynb) notebook to simulate three hours of pageview data. You can use the scripts in the [debug notebook](debug.ipynb) to read from Kafka topics to see if the messages are pushed correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app \"__main__\" (lazy loading)\n",
      " * Environment: production\n",
      "   WARNING: This is a development server. Do not use it in a production deployment.\n",
      "   Use a production WSGI server instead.\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on http://0.0.0.0:5000/ (Press CTRL+C to quit)\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import datetime\n",
    "import uuid\n",
    "import re\n",
    "import os\n",
    "from flask import Flask, request, Response, send_file, send_from_directory\n",
    "from kafka import KafkaProducer\n",
    "from IPython.display import clear_output\n",
    "\n",
    "app = Flask(__name__, static_url_path='')\n",
    "\n",
    "class Producer(object):\n",
    "    def __init__(self):\n",
    "        self.producer = KafkaProducer(bootstrap_servers=['localhost:9092'],\n",
    "                                      value_serializer=lambda v: json.dumps(v).encode('utf-8'))\n",
    "\n",
    "    def produce(self, topic, data):\n",
    "        self.producer.send(topic, data).get(timeout=30)\n",
    "\n",
    "\n",
    "producer = Producer()\n",
    "i = 0\n",
    "\n",
    "\n",
    "'''\n",
    "/clicks [POST]\n",
    "-----\n",
    "\n",
    "'''\n",
    "@app.route('/clicks', methods=['POST'])\n",
    "def extranm():\n",
    "    global i\n",
    "    if i > 1000:\n",
    "        clear_output()\n",
    "        i = 0\n",
    "    i = i+1\n",
    "    \n",
    "    rjson = request.json\n",
    "    \n",
    "    if not rjson:\n",
    "        return json.dumps({'success':False, 'message': 'could not decode json'}), 400, {'ContentType':'application/json'}\n",
    "\n",
    "    #print(rjson)\n",
    "    producer.produce('clicks', rjson)\n",
    "    return json.dumps({'success':True}), 200, {'ContentType':'application/json'}\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app.run(host='0.0.0.0')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
