{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating the input data for the realtime dashboard\n",
    "\n",
    "In this exercise, we'll use Spark structured streaming to generate the input data for the realtime dashboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: kafka-python in /opt/conda/lib/python3.9/site-packages (2.0.2)\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "# Install the required Python 3 dependencies\n",
    "python3 -m pip install kafka-python  # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from time import sleep\n",
    "import os\n",
    "os.environ['PYSPARK_SUBMIT_ARGS'] = '--packages org.apache.spark:spark-sql-kafka-0-10_2.12:3.2.0 pyspark-shell'\n",
    "\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "import pyspark \n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql.session import SparkSession\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "\n",
    "def test_query(sdf, mode=\"append\", rows=None, wait=2, sort=None):\n",
    "    # If a query with the same name exists, stop it.\n",
    "    query_name = \"test_query\"\n",
    "    query = None\n",
    "    for q in spark.streams.active:\n",
    "        if (q.name == query_name):\n",
    "            query = q\n",
    "    if query is not None:\n",
    "        query.stop()\n",
    "\n",
    "    try:\n",
    "        tq = (\n",
    "            # Create an output stream\n",
    "            sdf.writeStream               \n",
    "            # Only write new rows to the output\n",
    "            .outputMode(mode)           \n",
    "            # Write output stream to an in-memory Spark table (a DataFrame)\n",
    "            .format(\"memory\")               \n",
    "            # The name of the output table will be the same as the name of the query\n",
    "            .queryName(query_name)\n",
    "            # Submit the query to Spark and execute it\n",
    "            .start()\n",
    "        )\n",
    "\n",
    "        tq.processAllAvailable()\n",
    "\n",
    "        sleep(wait)\n",
    "        while(tq.status.get(\"isTriggerActive\") == True):\n",
    "            print(f\"DataAvailable: {tq.status['isDataAvailable']},\\tTriggerActive: {tq.status['isTriggerActive']}\\t{tq.status['message']}\")\n",
    "            sleep(wait)\n",
    "\n",
    "        # When the status says \"Waiting for data to arrive\", that means the query\n",
    "        # has finished its current iteration and is waiting for new messages from\n",
    "        # Kafka.\n",
    "        print(f\"DataAvailable: {tq.status['isDataAvailable']},\\tTriggerActive: {tq.status['isTriggerActive']}\\t{tq.status['message']}\")\n",
    "\n",
    "        memory_sink = spark.table(query_name)\n",
    "\n",
    "        if sort:\n",
    "            memory_sink = memory_sink.sort(*sort)\n",
    "\n",
    "        # Show result table in Jupyter Notebook. Since Jupyter Notebooks have native support for showing pandas tables,\n",
    "        # we convert the Spark DataFrame.\n",
    "        if rows:\n",
    "            display(memory_sink)\n",
    "            display(memory_sink.take(10))\n",
    "        else:\n",
    "            display(memory_sink)\n",
    "            display(memory_sink.toPandas())\n",
    "\n",
    "    finally:\n",
    "        # Always try to stop the query but it doesn't matter if it fails.\n",
    "        try:\n",
    "            tq.stop()\n",
    "        except:\n",
    "            pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a Spark context and specify that the python spark-kafka libraries need to be added."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/usr/local/spark-3.2.0-bin-hadoop3.2/jars/spark-unsafe_2.12-3.2.0.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Ivy Default Cache set to: /home/jovyan/.ivy2/cache\n",
      "The jars for the packages stored in: /home/jovyan/.ivy2/jars\n",
      "org.apache.spark#spark-sql-kafka-0-10_2.12 added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-67178843-b4fd-4d1c-8194-878ed34780c6;1.0\n",
      "\tconfs: [default]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/usr/local/spark-3.2.0-bin-hadoop3.2/jars/ivy-2.5.0.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tfound org.apache.spark#spark-sql-kafka-0-10_2.12;3.2.0 in central\n",
      "\tfound org.apache.spark#spark-token-provider-kafka-0-10_2.12;3.2.0 in central\n",
      "\tfound org.apache.kafka#kafka-clients;2.8.0 in central\n",
      "\tfound org.lz4#lz4-java;1.7.1 in central\n",
      "\tfound org.xerial.snappy#snappy-java;1.1.8.4 in central\n",
      "\tfound org.slf4j#slf4j-api;1.7.30 in central\n",
      "\tfound org.apache.hadoop#hadoop-client-runtime;3.3.1 in central\n",
      "\tfound org.spark-project.spark#unused;1.0.0 in central\n",
      "\tfound org.apache.hadoop#hadoop-client-api;3.3.1 in central\n",
      "\tfound org.apache.htrace#htrace-core4;4.1.0-incubating in central\n",
      "\tfound commons-logging#commons-logging;1.1.3 in central\n",
      "\tfound com.google.code.findbugs#jsr305;3.0.0 in central\n",
      "\tfound org.apache.commons#commons-pool2;2.6.2 in central\n",
      ":: resolution report :: resolve 381ms :: artifacts dl 7ms\n",
      "\t:: modules in use:\n",
      "\tcom.google.code.findbugs#jsr305;3.0.0 from central in [default]\n",
      "\tcommons-logging#commons-logging;1.1.3 from central in [default]\n",
      "\torg.apache.commons#commons-pool2;2.6.2 from central in [default]\n",
      "\torg.apache.hadoop#hadoop-client-api;3.3.1 from central in [default]\n",
      "\torg.apache.hadoop#hadoop-client-runtime;3.3.1 from central in [default]\n",
      "\torg.apache.htrace#htrace-core4;4.1.0-incubating from central in [default]\n",
      "\torg.apache.kafka#kafka-clients;2.8.0 from central in [default]\n",
      "\torg.apache.spark#spark-sql-kafka-0-10_2.12;3.2.0 from central in [default]\n",
      "\torg.apache.spark#spark-token-provider-kafka-0-10_2.12;3.2.0 from central in [default]\n",
      "\torg.lz4#lz4-java;1.7.1 from central in [default]\n",
      "\torg.slf4j#slf4j-api;1.7.30 from central in [default]\n",
      "\torg.spark-project.spark#unused;1.0.0 from central in [default]\n",
      "\torg.xerial.snappy#snappy-java;1.1.8.4 from central in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   13  |   0   |   0   |   0   ||   13  |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-67178843-b4fd-4d1c-8194-878ed34780c6\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 13 already retrieved (0kB/5ms)\n",
      "21/12/13 00:24:17 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "21/12/13 00:24:18 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "21/12/13 00:24:18 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n"
     ]
    }
   ],
   "source": [
    "# Create a local Spark cluster with two executors (if it doesn't already exist)\n",
    "spark = SparkSession.builder.master('local[2]').getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a streaming DataFrame that represents the events received from the Kafka topic `clicks-cleaned`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21/12/13 00:24:23 WARN ResolveWriteToStream: Temporary checkpoint location created which is deleted normally when the query didn't fail: /tmp/temporary-ea34d396-87cf-49cf-86ce-ef173b21bd39. If it's required to delete it under any circumstances, please set spark.sql.streaming.forceDeleteTempCheckpointLocation to true. Important to know deleting temp checkpoint folder is best effort.\n",
      "21/12/13 00:24:23 WARN ResolveWriteToStream: spark.sql.adaptive.enabled is not supported in streaming DataFrames/Datasets and will be disabled.\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataAvailable: False,\tTriggerActive: False\tWaiting for data to arrive\n",
      "DataAvailable: False,\tTriggerActive: False\tWaiting for data to arrive\n",
      "DataAvailable: False,\tTriggerActive: False\tWaiting for data to arrive\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[key: binary, value: binary, topic: string, partition: int, offset: bigint, timestamp: timestamp, timestampType: int]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key</th>\n",
       "      <th>value</th>\n",
       "      <th>topic</th>\n",
       "      <th>partition</th>\n",
       "      <th>offset</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>timestampType</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "      <td>[123, 34, 118, 105, 115, 105, 116, 111, 114, 9...</td>\n",
       "      <td>clicks-cleaned</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-12-12 21:54:42.497</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>None</td>\n",
       "      <td>[123, 34, 118, 105, 115, 105, 116, 111, 114, 9...</td>\n",
       "      <td>clicks-cleaned</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2021-12-12 21:54:42.505</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>None</td>\n",
       "      <td>[123, 34, 118, 105, 115, 105, 116, 111, 114, 9...</td>\n",
       "      <td>clicks-cleaned</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2021-12-12 21:54:42.506</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>None</td>\n",
       "      <td>[123, 34, 118, 105, 115, 105, 116, 111, 114, 9...</td>\n",
       "      <td>clicks-cleaned</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2021-12-12 21:54:42.592</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>None</td>\n",
       "      <td>[123, 34, 118, 105, 115, 105, 116, 111, 114, 9...</td>\n",
       "      <td>clicks-cleaned</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2021-12-12 21:54:42.593</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>None</td>\n",
       "      <td>[123, 34, 118, 105, 115, 105, 116, 111, 114, 9...</td>\n",
       "      <td>clicks-cleaned</td>\n",
       "      <td>0</td>\n",
       "      <td>72</td>\n",
       "      <td>2021-12-12 21:54:43.893</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>None</td>\n",
       "      <td>[123, 34, 118, 105, 115, 105, 116, 111, 114, 9...</td>\n",
       "      <td>clicks-cleaned</td>\n",
       "      <td>0</td>\n",
       "      <td>73</td>\n",
       "      <td>2021-12-12 21:54:43.893</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>None</td>\n",
       "      <td>[123, 34, 118, 105, 115, 105, 116, 111, 114, 9...</td>\n",
       "      <td>clicks-cleaned</td>\n",
       "      <td>0</td>\n",
       "      <td>74</td>\n",
       "      <td>2021-12-12 21:54:43.893</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>None</td>\n",
       "      <td>[123, 34, 118, 105, 115, 105, 116, 111, 114, 9...</td>\n",
       "      <td>clicks-cleaned</td>\n",
       "      <td>0</td>\n",
       "      <td>75</td>\n",
       "      <td>2021-12-12 21:54:43.893</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>None</td>\n",
       "      <td>[123, 34, 118, 105, 115, 105, 116, 111, 114, 9...</td>\n",
       "      <td>clicks-cleaned</td>\n",
       "      <td>0</td>\n",
       "      <td>76</td>\n",
       "      <td>2021-12-12 21:54:43.894</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>77 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     key                                              value           topic  \\\n",
       "0   None  [123, 34, 118, 105, 115, 105, 116, 111, 114, 9...  clicks-cleaned   \n",
       "1   None  [123, 34, 118, 105, 115, 105, 116, 111, 114, 9...  clicks-cleaned   \n",
       "2   None  [123, 34, 118, 105, 115, 105, 116, 111, 114, 9...  clicks-cleaned   \n",
       "3   None  [123, 34, 118, 105, 115, 105, 116, 111, 114, 9...  clicks-cleaned   \n",
       "4   None  [123, 34, 118, 105, 115, 105, 116, 111, 114, 9...  clicks-cleaned   \n",
       "..   ...                                                ...             ...   \n",
       "72  None  [123, 34, 118, 105, 115, 105, 116, 111, 114, 9...  clicks-cleaned   \n",
       "73  None  [123, 34, 118, 105, 115, 105, 116, 111, 114, 9...  clicks-cleaned   \n",
       "74  None  [123, 34, 118, 105, 115, 105, 116, 111, 114, 9...  clicks-cleaned   \n",
       "75  None  [123, 34, 118, 105, 115, 105, 116, 111, 114, 9...  clicks-cleaned   \n",
       "76  None  [123, 34, 118, 105, 115, 105, 116, 111, 114, 9...  clicks-cleaned   \n",
       "\n",
       "    partition  offset               timestamp  timestampType  \n",
       "0           0       0 2021-12-12 21:54:42.497              0  \n",
       "1           0       1 2021-12-12 21:54:42.505              0  \n",
       "2           0       2 2021-12-12 21:54:42.506              0  \n",
       "3           0       3 2021-12-12 21:54:42.592              0  \n",
       "4           0       4 2021-12-12 21:54:42.593              0  \n",
       "..        ...     ...                     ...            ...  \n",
       "72          0      72 2021-12-12 21:54:43.893              0  \n",
       "73          0      73 2021-12-12 21:54:43.893              0  \n",
       "74          0      74 2021-12-12 21:54:43.893              0  \n",
       "75          0      75 2021-12-12 21:54:43.893              0  \n",
       "76          0      76 2021-12-12 21:54:43.894              0  \n",
       "\n",
       "[77 rows x 7 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "input = (\n",
    "    spark.readStream.format(\"kafka\")\n",
    "    # The Kafka server is available on localhost port 9092\n",
    "    .option(\"kafka.bootstrap.servers\",\"localhost:9092\")\n",
    "    # Read the \"clicks-cleaned\" topic\n",
    "    .option(\"subscribe\", \"clicks-cleaned\")\n",
    "    # Start at the beginning of this topic. This will read all historical data from Kafka.\n",
    "    # Use \"latest\" if you only want to process _new_ events.\n",
    "    .option(\"startingOffsets\", \"earliest\")\n",
    "    # Process a maximum of 5 offsets per trigger\n",
    "    .option(\"maxOffsetsPerTrigger\", \"5\")\n",
    "    # Return a Streaming DataFrame representing this stream\n",
    "    .load()\n",
    ")\n",
    "\n",
    "test_query(input, mode=\"append\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cast the json to columns in the DataFrame. Make sure to use TimestampType for the `ts_ingest` since we already converted it in the `clean` notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21/12/13 00:25:40 WARN ResolveWriteToStream: Temporary checkpoint location created which is deleted normally when the query didn't fail: /tmp/temporary-e2d44e4b-b98e-4de2-b9be-2a9fe221622f. If it's required to delete it under any circumstances, please set spark.sql.streaming.forceDeleteTempCheckpointLocation to true. Important to know deleting temp checkpoint folder is best effort.\n",
      "21/12/13 00:25:40 WARN ResolveWriteToStream: spark.sql.adaptive.enabled is not supported in streaming DataFrames/Datasets and will be disabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataAvailable: False,\tTriggerActive: False\tWaiting for data to arrive\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[visitor_platform: string, ts_ingest: timestamp, article_title: string, visitor_country: string, visitor_os: string, article: string, visitor_browser: string, visitor_page_timer: int, visitor_page_height: int]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>visitor_platform</th>\n",
       "      <th>ts_ingest</th>\n",
       "      <th>article_title</th>\n",
       "      <th>visitor_country</th>\n",
       "      <th>visitor_os</th>\n",
       "      <th>article</th>\n",
       "      <th>visitor_browser</th>\n",
       "      <th>visitor_page_timer</th>\n",
       "      <th>visitor_page_height</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mobile</td>\n",
       "      <td>2021-12-12 21:29:03</td>\n",
       "      <td>Cercanías San Sebastián</td>\n",
       "      <td>BE</td>\n",
       "      <td>ios</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Cercan%C3%ADas_S...</td>\n",
       "      <td>unknown</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mobile</td>\n",
       "      <td>2021-12-12 21:29:03</td>\n",
       "      <td>Kingdom of Hawaii</td>\n",
       "      <td>BE</td>\n",
       "      <td>ios</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Kingdom_of_Hawaii</td>\n",
       "      <td>unknown</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>desktop</td>\n",
       "      <td>2021-12-12 21:29:03</td>\n",
       "      <td>Republican National Coalition for Life</td>\n",
       "      <td>BE</td>\n",
       "      <td>windows</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Republican_Natio...</td>\n",
       "      <td>firefox</td>\n",
       "      <td>4350</td>\n",
       "      <td>18743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>desktop</td>\n",
       "      <td>2021-12-12 21:29:03</td>\n",
       "      <td>Black Mesa (Warm Springs, Arizona)</td>\n",
       "      <td>BE</td>\n",
       "      <td>windows</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Black_Mesa_(Warm...</td>\n",
       "      <td>unknown</td>\n",
       "      <td>1117</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>desktop</td>\n",
       "      <td>2021-12-12 21:29:03</td>\n",
       "      <td>Lavalle House</td>\n",
       "      <td>BE</td>\n",
       "      <td>windows</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Lavalle_House</td>\n",
       "      <td>chrome</td>\n",
       "      <td>1409</td>\n",
       "      <td>39838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>mobile</td>\n",
       "      <td>2021-12-12 21:29:06</td>\n",
       "      <td>Kingdom of Hawaii</td>\n",
       "      <td>BE</td>\n",
       "      <td>ios</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Kingdom_of_Hawaii</td>\n",
       "      <td>unknown</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>mobile</td>\n",
       "      <td>2021-12-12 21:29:06</td>\n",
       "      <td>Sky (company)</td>\n",
       "      <td>BE</td>\n",
       "      <td>ios</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Sky_(company)</td>\n",
       "      <td>unknown</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>tablet</td>\n",
       "      <td>2021-12-12 21:29:06</td>\n",
       "      <td>2010 North African Super Cup</td>\n",
       "      <td>BE</td>\n",
       "      <td>ios</td>\n",
       "      <td>https://en.wikipedia.org/wiki/2010_North_Afric...</td>\n",
       "      <td>safari</td>\n",
       "      <td>12222</td>\n",
       "      <td>4175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>desktop</td>\n",
       "      <td>2021-12-12 21:29:06</td>\n",
       "      <td>Randomized algorithm</td>\n",
       "      <td>BE</td>\n",
       "      <td>mac</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Randomized_algor...</td>\n",
       "      <td>safari</td>\n",
       "      <td>584</td>\n",
       "      <td>5465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>tablet</td>\n",
       "      <td>2021-12-12 21:29:06</td>\n",
       "      <td>Chica da Silva</td>\n",
       "      <td>BE</td>\n",
       "      <td>ios</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Chica_da_Silva</td>\n",
       "      <td>unknown</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>77 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   visitor_platform           ts_ingest  \\\n",
       "0            mobile 2021-12-12 21:29:03   \n",
       "1            mobile 2021-12-12 21:29:03   \n",
       "2           desktop 2021-12-12 21:29:03   \n",
       "3           desktop 2021-12-12 21:29:03   \n",
       "4           desktop 2021-12-12 21:29:03   \n",
       "..              ...                 ...   \n",
       "72           mobile 2021-12-12 21:29:06   \n",
       "73           mobile 2021-12-12 21:29:06   \n",
       "74           tablet 2021-12-12 21:29:06   \n",
       "75          desktop 2021-12-12 21:29:06   \n",
       "76           tablet 2021-12-12 21:29:06   \n",
       "\n",
       "                             article_title visitor_country visitor_os  \\\n",
       "0                  Cercanías San Sebastián              BE        ios   \n",
       "1                        Kingdom of Hawaii              BE        ios   \n",
       "2   Republican National Coalition for Life              BE    windows   \n",
       "3       Black Mesa (Warm Springs, Arizona)              BE    windows   \n",
       "4                            Lavalle House              BE    windows   \n",
       "..                                     ...             ...        ...   \n",
       "72                       Kingdom of Hawaii              BE        ios   \n",
       "73                           Sky (company)              BE        ios   \n",
       "74            2010 North African Super Cup              BE        ios   \n",
       "75                    Randomized algorithm              BE        mac   \n",
       "76                          Chica da Silva              BE        ios   \n",
       "\n",
       "                                              article visitor_browser  \\\n",
       "0   https://en.wikipedia.org/wiki/Cercan%C3%ADas_S...         unknown   \n",
       "1     https://en.wikipedia.org/wiki/Kingdom_of_Hawaii         unknown   \n",
       "2   https://en.wikipedia.org/wiki/Republican_Natio...         firefox   \n",
       "3   https://en.wikipedia.org/wiki/Black_Mesa_(Warm...         unknown   \n",
       "4         https://en.wikipedia.org/wiki/Lavalle_House          chrome   \n",
       "..                                                ...             ...   \n",
       "72    https://en.wikipedia.org/wiki/Kingdom_of_Hawaii         unknown   \n",
       "73        https://en.wikipedia.org/wiki/Sky_(company)         unknown   \n",
       "74  https://en.wikipedia.org/wiki/2010_North_Afric...          safari   \n",
       "75  https://en.wikipedia.org/wiki/Randomized_algor...          safari   \n",
       "76       https://en.wikipedia.org/wiki/Chica_da_Silva         unknown   \n",
       "\n",
       "    visitor_page_timer  visitor_page_height  \n",
       "0                    0                    0  \n",
       "1                    0                    0  \n",
       "2                 4350                18743  \n",
       "3                 1117                 5000  \n",
       "4                 1409                39838  \n",
       "..                 ...                  ...  \n",
       "72                   0                    0  \n",
       "73                   0                    0  \n",
       "74               12222                 4175  \n",
       "75                 584                 5465  \n",
       "76                   0                    0  \n",
       "\n",
       "[77 rows x 9 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "schema = StructType([\n",
    "    StructField(\"visitor_platform\", StringType()),\n",
    "    StructField(\"ts_ingest\", TimestampType()),\n",
    "    StructField(\"article_title\", StringType()),\n",
    "    StructField(\"visitor_country\", StringType()),\n",
    "    StructField(\"visitor_os\", StringType()),\n",
    "    StructField(\"article\", StringType()),\n",
    "    StructField(\"visitor_browser\", StringType()),\n",
    "    StructField(\"visitor_page_timer\", IntegerType()),\n",
    "    StructField(\"visitor_page_height\", IntegerType()),\n",
    "])\n",
    "\n",
    "dfs = input.selectExpr(\"CAST(value AS STRING)\") \\\n",
    "      .select(from_json(col(\"value\"), schema) \\\n",
    "      .alias(\"clicks\"))\n",
    "\n",
    "df_data = dfs.select(\"clicks.*\")\n",
    "\n",
    "test_query(df_data, mode=\"append\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate the values you want to show in your dashboard. You are free to choose which values and aggregations to show. As an example, you can group by article title and use a 10 seconds window in order to show how many views each article received."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21/12/13 00:28:02 WARN ResolveWriteToStream: Temporary checkpoint location created which is deleted normally when the query didn't fail: /tmp/temporary-8881f705-6b72-4abb-9d17-e474a80f4150. If it's required to delete it under any circumstances, please set spark.sql.streaming.forceDeleteTempCheckpointLocation to true. Important to know deleting temp checkpoint folder is best effort.\n",
      "21/12/13 00:28:02 WARN ResolveWriteToStream: spark.sql.adaptive.enabled is not supported in streaming DataFrames/Datasets and will be disabled.\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataAvailable: False,\tTriggerActive: False\tWaiting for data to arrive\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[article_title: string, window: struct<start:timestamp,end:timestamp>, count: bigint]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_title</th>\n",
       "      <th>window</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cercanías San Sebastián</td>\n",
       "      <td>(2021-12-12 21:29:02, 2021-12-12 21:29:04)</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>To Be a Millionaire</td>\n",
       "      <td>(2021-12-12 21:29:02, 2021-12-12 21:29:04)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A540 road</td>\n",
       "      <td>(2021-12-12 21:29:02, 2021-12-12 21:29:04)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Intersex rights in Uganda</td>\n",
       "      <td>(2021-12-12 21:29:02, 2021-12-12 21:29:04)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Granada Theater (Dallas)</td>\n",
       "      <td>(2021-12-12 21:29:02, 2021-12-12 21:29:04)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Republican National Coalition for Life</td>\n",
       "      <td>(2021-12-12 21:29:02, 2021-12-12 21:29:04)</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Battle of Cuddalore (1758)</td>\n",
       "      <td>(2021-12-12 21:29:02, 2021-12-12 21:29:04)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Black Mesa (Warm Springs, Arizona)</td>\n",
       "      <td>(2021-12-12 21:29:02, 2021-12-12 21:29:04)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1982 Daytona 500</td>\n",
       "      <td>(2021-12-12 21:29:02, 2021-12-12 21:29:04)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Sternbergia candida</td>\n",
       "      <td>(2021-12-12 21:29:02, 2021-12-12 21:29:04)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Kingdom of Hawaii</td>\n",
       "      <td>(2021-12-12 21:29:02, 2021-12-12 21:29:04)</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Lavalle House</td>\n",
       "      <td>(2021-12-12 21:29:02, 2021-12-12 21:29:04)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             article_title  \\\n",
       "0                  Cercanías San Sebastián   \n",
       "1                      To Be a Millionaire   \n",
       "2                                A540 road   \n",
       "3                Intersex rights in Uganda   \n",
       "4                 Granada Theater (Dallas)   \n",
       "5   Republican National Coalition for Life   \n",
       "6               Battle of Cuddalore (1758)   \n",
       "7       Black Mesa (Warm Springs, Arizona)   \n",
       "8                         1982 Daytona 500   \n",
       "9                      Sternbergia candida   \n",
       "10                       Kingdom of Hawaii   \n",
       "11                           Lavalle House   \n",
       "\n",
       "                                        window  count  \n",
       "0   (2021-12-12 21:29:02, 2021-12-12 21:29:04)      2  \n",
       "1   (2021-12-12 21:29:02, 2021-12-12 21:29:04)      1  \n",
       "2   (2021-12-12 21:29:02, 2021-12-12 21:29:04)      1  \n",
       "3   (2021-12-12 21:29:02, 2021-12-12 21:29:04)      1  \n",
       "4   (2021-12-12 21:29:02, 2021-12-12 21:29:04)      1  \n",
       "5   (2021-12-12 21:29:02, 2021-12-12 21:29:04)      4  \n",
       "6   (2021-12-12 21:29:02, 2021-12-12 21:29:04)      1  \n",
       "7   (2021-12-12 21:29:02, 2021-12-12 21:29:04)      1  \n",
       "8   (2021-12-12 21:29:02, 2021-12-12 21:29:04)      1  \n",
       "9   (2021-12-12 21:29:02, 2021-12-12 21:29:04)      1  \n",
       "10  (2021-12-12 21:29:02, 2021-12-12 21:29:04)      2  \n",
       "11  (2021-12-12 21:29:02, 2021-12-12 21:29:04)      1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_data_grouped = (\n",
    "    df_data\n",
    "        .withWatermark(\"ts_ingest\", \"1 second\")\n",
    "        .groupBy(\n",
    "            col('article_title'),\n",
    "            window(col('ts_ingest'), \"2 seconds\"))\n",
    "        .count()     \n",
    ")\n",
    "\n",
    "test_query(df_data_grouped, mode=\"append\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
