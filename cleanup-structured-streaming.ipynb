{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['PYSPARK_SUBMIT_ARGS'] = '--packages org.apache.spark:spark-sql-kafka-0-10_2.11:2.4.3 pyspark-shell'\n",
    "\n",
    "import pyspark \n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql.session import SparkSession\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.streaming import StreamingContext\n",
    "from pyspark.streaming.kafka import KafkaUtils\n",
    "\n",
    "\n",
    "sc = SparkContext()\n",
    "sc.setLogLevel(\"WARN\")\n",
    "spark = SparkSession(sc)\n",
    "\n",
    "\n",
    "df = spark.readStream.format(\"kafka\") \\\n",
    "    .option(\"kafka.bootstrap.servers\",\"10.10.139.63:9092\") \\\n",
    "    .option(\"subscribe\", \"inputs.testing\") \\\n",
    "    .option(\"startingOffsets\", \"earliest\") \\\n",
    "    .load()\n",
    "df.selectExpr(\"CAST(key AS STRING)\", \"CAST(value AS STRING)\")\n",
    "\n",
    "schema = StructType([\n",
    "    StructField(\"visitor_platform\", StringType()),\n",
    "    StructField(\"ts_ingest\", LongType()),\n",
    "    StructField(\"article_title\", StringType()),\n",
    "    StructField(\"visitor_country\", StringType()),\n",
    "    StructField(\"visitor_os\", StringType()),\n",
    "    StructField(\"article\", StringType()),\n",
    "    StructField(\"visitor_browser\", StringType()),\n",
    "    StructField(\"visitor_page_timer\", IntegerType()),\n",
    "    StructField(\"visitor_page_height\", IntegerType()),\n",
    "])\n",
    "\n",
    "dfs = df.selectExpr(\"CAST(value AS STRING)\") \\\n",
    "      .select(from_json(col(\"value\"), schema) \\\n",
    "      .alias(\"clicks\"))\n",
    "\n",
    "df_data = dfs.select(\"clicks.*\")\n",
    "# Drop row if it has a null field (https://spark.apache.org/docs/2.2.0/api/java/org/apache/spark/sql/DataFrameNaFunctions.html)\n",
    "df_data = df_data.na.drop()\n",
    "\n",
    "# Alter column ts_ingest to convert epochs (milli) to yyyy-mm-dd HH:MM:ss format\n",
    "df_DateConvertedString = df_data.withColumn(\"ts_ingest\", from_unixtime(df_data['ts_ingest']/1000))\n",
    "# ts_ingest column is of type String, needs to be converted to TimestampType\n",
    "df_DateConverted = df_DateConvertedString.withColumn('ts_ingest', to_timestamp(df_DateConvertedString['ts_ingest'].cast(dataType=TimestampType())))\n",
    "\n",
    "# Ensure that country codes are upper case\n",
    "df_end = df_DateConverted.withColumn(\"visitor_country\", upper(df_DateConverted['visitor_country']))\n",
    "\n",
    "# Filter out only BE and NL clicks\n",
    "df_be = df_end.filter((col(\"visitor_country\") == 'BE') | (col(\"visitor_country\") == 'NL'))\n",
    "\n",
    "#Debug to terminal\n",
    "# query = df_be.writeStream.outputMode(\"append\").option(\"truncate\", \"false\").format(\"console\").start()\n",
    "\n",
    "# Prepare df for Kafka and write to kafka\n",
    "query = df_be.selectExpr(\"to_json(struct(*)) as value\") \\\n",
    "    .writeStream.format(\"kafka\") \\\n",
    "    .option(\"kafka.bootstrap.servers\", \"10.10.139.63:9092\") \\\n",
    "    .option(\"topic\", \"calculated\") \\\n",
    "    .option(\"checkpointLocation\", \"checkpoints\") \\\n",
    "    .start()\n",
    "\n",
    "query.awaitTermination()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
