{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['PYSPARK_SUBMIT_ARGS'] = '--packages org.apache.spark:spark-sql-kafka-0-10_2.11:2.4.3 pyspark-shell'\n",
    "\n",
    "import pyspark \n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql.session import SparkSession\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.streaming import StreamingContext\n",
    "from pyspark.streaming.kafka import KafkaUtils\n",
    "\n",
    "\n",
    "sc = SparkContext()\n",
    "sc.setLogLevel(\"WARN\")\n",
    "spark = SparkSession(sc)\n",
    "\n",
    "\n",
    "df = spark.readStream.format(\"kafka\") \\\n",
    "    .option(\"kafka.bootstrap.servers\",\"10.10.139.63:9092\") \\\n",
    "    .option(\"subscribe\", \"calculated\") \\\n",
    "    .option(\"startingOffsets\", \"earliest\") \\\n",
    "    .load()\n",
    "df.selectExpr(\"CAST(key AS STRING)\", \"CAST(value AS STRING)\")\n",
    "\n",
    "schema = StructType([\n",
    "    StructField(\"visitor_platform\", StringType()),\n",
    "    StructField(\"ts_ingest\", TimestampType()),\n",
    "    StructField(\"article_title\", StringType()),\n",
    "    StructField(\"visitor_country\", StringType()),\n",
    "    StructField(\"visitor_os\", StringType()),\n",
    "    StructField(\"article\", StringType()),\n",
    "    StructField(\"visitor_browser\", StringType()),\n",
    "    StructField(\"visitor_page_timer\", IntegerType()),\n",
    "    StructField(\"visitor_page_height\", IntegerType()),\n",
    "])\n",
    "\n",
    "dfs = df.selectExpr(\"CAST(value AS STRING)\") \\\n",
    "      .select(from_json(col(\"value\"), schema) \\\n",
    "      .alias(\"clicks\"))\n",
    "\n",
    "df_data = dfs.select(\"clicks.*\")\n",
    "\n",
    "# TODO use Mailgun and prevent spamming yourself with emails\n",
    "@udf\n",
    "def forbidden_clicks(click_url):\n",
    "    print(click_url)\n",
    "    if click_url.endswith('/admin'):\n",
    "        print('SECURITY BREACH! Someone is trying to access {}\\n'.format(click_url))\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "# For every article url let's check if it is a forbidden url\n",
    "# We can not use the map() function here, dataframes do not support this anymore since version 2.0\n",
    "# Under the hood calling map() on a dataframe would transform it to an rdd which is not allowed in structured streaming\n",
    "# It means you can use only DataFrame or SQL, conversion to RDD (or DStream or local collections) are not supported.\n",
    "# For this we will use a User Defined Function (UDF) to execute some Pyhton code on a column.\n",
    "df_forbidden = df_data.select('article', forbidden_clicks('article').alias('forbidden'))\n",
    "\n",
    "# DDOS\n",
    "# Window over last X minutes, count number of 'visitor_page_timer' and 'visitor_page_height' == 0\n",
    "# If over threshold then alert\n",
    "\n",
    "\n",
    "# TODO use Mailgun and prevent spamming yourself with emails\n",
    "@udf\n",
    "def ddos_clicks(count):\n",
    "    if count > 1:\n",
    "        print('DDOS?\\n')\n",
    "        return \"DDOS\"\n",
    "    return \"--\"\n",
    "\n",
    "df_ddos = df_data.groupBy(\n",
    "    window(df_data.ts_ingest, '10 seconds', '10 seconds'),\n",
    "    df_data.visitor_page_timer,\n",
    "    df_data.visitor_page_height    \n",
    ").count().select(\"window\", \"visitor_page_timer\", \"visitor_page_height\",'count', ddos_clicks('count').alias('ddos')) \\\n",
    "    .where('visitor_page_timer = 0 and visitor_page_height = 0')\n",
    "\n",
    "# Debug dataframes in terminal\n",
    "query_data = df_data.writeStream.outputMode(\"append\").option(\"truncate\", \"false\").format(\"console\").start()\n",
    "query_forbidden = df_forbidden.writeStream.outputMode(\"append\").option(\"truncate\", \"false\").format(\"console\").start()\n",
    "query_ddos = df_ddos.writeStream.outputMode(\"update\").option(\"truncate\", \"false\").format(\"console\").start()\n",
    "\n",
    "spark.streams.awaitAnyTermination()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
