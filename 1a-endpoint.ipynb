{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ingesting pageview data\n",
    "\n",
    "In this exercise, you create an HTTP endpoint that ingests page view data (clicks) into the platform. Every time a user clicks on a link and when the user scrolls to certain positions on the page, a json \"click\" objects gets sent to this endpoint.\n",
    "\n",
    "This is what a click event looks like.\n",
    "\n",
    "```json\n",
    "{\n",
    "    \"visitor_platform\": \"mobile\",\n",
    "    #\n",
    "    # Timestamp of the event (milliseconds since unix epoch)\n",
    "    \"ts_ingest\": 1515819844345,\n",
    "    \n",
    "    \"article_title\": \"Cercanías San Sebastián\",\n",
    "    \"visitor_country\": \"BE\",\n",
    "    \n",
    "    # Seconds the page was open before this event was sent.\n",
    "    # (0 when this event is sent immediately after the page was opened.)\n",
    "    \"visitor_page_timer\": 0,\n",
    "\n",
    "    \"visitor_os\": \"ios\",\n",
    "    \"article\": \"https://en.wikipedia.org/wiki/Cercan%C3%ADas_San_Sebasti%C3%A1n\",\n",
    "    \n",
    "    # How much the user scrolled before this event was sent.\n",
    "    # (0 when this event is sent while the user hasn't scrolled yet.)\n",
    "    \"visitor_page_height\": 0,\n",
    "    \n",
    "    \"visitor_browser\": \"unknown\"\n",
    "}\n",
    "```\n",
    "\n",
    "\n",
    "We use the [Python Flask framework](http://flask.pocoo.org/) to create the ingest HTTP endpoint. Flask is a lightweight and simple, but very powerful framework to write HTTP webservers in Python. Flask powers the api's of many large web services such as [Netflix](https://medium.com/netflix-techblog/python-at-netflix-bba45dae649e), [Airbnb](https://medium.com/airbnb-engineering/airflow-a-workflow-management-platform-46318b977fd8), [Uber](https://github.com/uber/clay) and [Reddit](https://stackshare.io/reddit/reddit).\n",
    "\n",
    "## Apache Kafka as event store\n",
    "\n",
    "The clicks that our API recieves are stored in [Apache Kafka](https://kafka.apache.org/), a distributed streaming platform initially created by LinkedIn. Kafka stores large distributed queues, called *topics* and allows *producers* to send data to the queue and *consumers* to read data from the queue, all in a fault-tolerant and durable way.\n",
    "\n",
    "The sole responsibility of the Ingest API is to recieve click events from HTTP POST requests and put them on the `clicks` topic in Kafka. The Ingest API itself doesn't do any cleaning or filtering, this happens later in the pipeline. Using Kafka here has a number of advantages.\n",
    "\n",
    "* Kafka acts as a **buffer** between the ingest of events and the processing events. Downstream issues, such as the processing code crashing, don't affect the ingest of events. This also allows the platform to **gracefully handle spikes in load**. When the processing code can't handle the load, Kafka will gather a backlog of unprocessed events, but the events will not be lost and the processing code can catch up when the load decreases again.\n",
    "* Kafka allows multiple consumers to subscribe to the same topic. This makes it easy to have **multiple paralell processing pipelines** which recieve the same event stream. You can use this to run multiple versions of your code next to each other in order to do tests or quality assurance. Or to have a staging environment that recieves the same event stream as the production environment.\n",
    "* Kafka is a **language-agnostic** platform with many client libraries so you can use it to create heterogenous streaming analytics pipelines.\n",
    "\n",
    "For long-term storage of the event log, you can couple Kafka with Hadoop and create a small service that persists the event log in HDFS. You can then replay the historic log using a producer that reads from HDFS, or you can process the event log in batch using a technology like Hadoop MapReduce or Spark.\n",
    "\n",
    "So, to start the exercise, let's install the required dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: kafka-python in /opt/conda/lib/python3.9/site-packages (2.0.2)\n",
      "Collecting flask\n",
      "  Downloading Flask-2.0.2-py3-none-any.whl (95 kB)\n",
      "Requirement already satisfied: click>=7.1.2 in /opt/conda/lib/python3.9/site-packages (from flask) (8.0.3)\n",
      "Collecting itsdangerous>=2.0\n",
      "  Downloading itsdangerous-2.0.1-py3-none-any.whl (18 kB)\n",
      "Collecting Werkzeug>=2.0\n",
      "  Downloading Werkzeug-2.0.2-py3-none-any.whl (288 kB)\n",
      "Requirement already satisfied: Jinja2>=3.0 in /opt/conda/lib/python3.9/site-packages (from flask) (3.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.9/site-packages (from Jinja2>=3.0->flask) (2.0.1)\n",
      "Installing collected packages: Werkzeug, itsdangerous, flask\n",
      "Successfully installed Werkzeug-2.0.2 flask-2.0.2 itsdangerous-2.0.1\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "# Install the required Python 3 dependencies\n",
    "python3 -m pip install kafka-python flask  # type: ignore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flask introduction\n",
    "\n",
    "The following code snippet is everything you need to get a working \"Hello World\" HTTP api. You start the server by running the cell. (select the cell with the python code and press `ctrl`-`enter`).\n",
    "\n",
    "\n",
    "> Note: in a Jupyter notebook, only one cell can run at the same time. This webserver cell will keep running until it is killed, however. When you proceed to the next cell, **you need to manually stop this webserver** by clicking on the \"stop\" button on the toolbar of this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__' (lazy loading)\n",
      " * Environment: production\n",
      "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
      "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on all addresses.\n",
      "   WARNING: This is a development server. Do not use it in a production deployment.\n",
      " * Running on http://172.24.0.3:5000/ (Press CTRL+C to quit)\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask\n",
    "\n",
    "# Create a new webserver.\n",
    "app = Flask(__name__)\n",
    "\n",
    "# For each GET request to http://localhost/, send the string \"Index Page\" as response.\n",
    "@app.route('/')\n",
    "def index():\n",
    "    return 'Index Page\\n'\n",
    "\n",
    "# For each GET request to http://localhost/hello, send the string \"Hello, World\" as response.\n",
    "@app.route('/hello')\n",
    "def hello():\n",
    "    return 'Hello, World\\n'\n",
    "\n",
    "# Run the webserver and allow requests from any IP.\n",
    "if __name__ == \"__main__\":\n",
    "    app.run(host='0.0.0.0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can test the server by visiting [http://localhost:5000](http://localhost:5000), or by using the `curl` command in a terminal.\n",
    "\n",
    "```txt\n",
    "$ curl http://localhost:5000\n",
    "Index Page\n",
    "$ curl http://localhost:5000/hello\n",
    "Hello, World\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic functionality\n",
    "\n",
    "* By adding the `@app.route(\"/\")` annotation to a Python function, you define the URL that will execute it. In the above example, each call to `/` will run the `index` function. Such an annotated function is called a \"view function\". Take a look at [Flask quickstart - Routing](https://flask.palletsprojects.com/en/1.1.x/quickstart/#routing) for more information.\n",
    "* The return value of a view function gets processed by [`make_response()`](https://flask.palletsprojects.com/en/1.1.x/api/#flask.Flask.make_response) to turn it into an HTTP response. This function supports many different kinds of arguments. The simplest is a string, which will return the string as response body and use status code 200. You can also use a tuple to specify other response codes.\n",
    "* Flask has a global variable `flask.request`. You can use this to get the HTTP request headers, body and more. For example, `request.json` is a dictionary generated from the `json` body of the request. See [Incoming Request Data](https://flask.palletsprojects.com/en/1.1.x/api/#incoming-request-data) for more information.\n",
    "\n",
    "# Kafka introduction\n",
    "\n",
    "This VSCode workspace sets up two containers. The container you're working in now runs a Spark cluster and Jupyter. The second container runs Apache Kafka; the message queue used in our Kappa architecture. You can access the Kafka cluster from this container by connecting to `localhost:9092`.\n",
    "\n",
    "Below is an example for how to publish data to Kafka using Python. We use the [`python-kafka`](https://kafka-python.readthedocs.io/en/master/usage.html) package for this. Since Kafka is a distributed _queue_, we write data to Kafka by sending messages. The code writing data is called a producer. The code reading the data is called a consumer.\n",
    "\n",
    "> Note: if you encounter a `NoBrokersAvailable` error message, that means that the Kafka server is not reachable. Something must have gone wrong with running the containers. We suggest pressing the green \"Remote\" button on the bottom left of VSCode and choosing \"rebuild container\". If this doesn't work, you should manually remove all containers and restart VSCode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RecordMetadata(topic='test-topic', partition=0, topic_partition=TopicPartition(topic='test-topic', partition=0), offset=8, timestamp=1639361786376, log_start_offset=0, checksum=None, serialized_key_size=-1, serialized_value_size=3, serialized_header_size=-1)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from kafka import KafkaProducer\n",
    "\n",
    "topic =\"test-topic\"\n",
    "\n",
    "producer = KafkaProducer(\n",
    "    bootstrap_servers=['localhost:9092'])\n",
    "\n",
    "# Note: The data you send must be binary\n",
    "producer.send(topic, b\"Hello World!\").get(timeout=30)\n",
    "producer.send(topic, b\"Foo\").get(timeout=30)\n",
    "producer.send(topic, b\"Bar\").get(timeout=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test-topic:0:0: key=None value=b'Hello World!'\n",
      "test-topic:0:1: key=None value=b'Foo'\n",
      "test-topic:0:2: key=None value=b'Bar'\n",
      "test-topic:0:3: key=None value=b'Hello World!'\n",
      "test-topic:0:4: key=None value=b'Foo'\n",
      "test-topic:0:5: key=None value=b'Bar'\n",
      "test-topic:0:6: key=None value=b'Hello World!'\n",
      "test-topic:0:7: key=None value=b'Foo'\n",
      "test-topic:0:8: key=None value=b'Bar'\n"
     ]
    }
   ],
   "source": [
    "from kafka import KafkaConsumer, TopicPartition\n",
    "\n",
    "\n",
    "# To consume latest messages and auto-commit offsets\n",
    "consumer = KafkaConsumer(\n",
    "    bootstrap_servers=['localhost:9092'],\n",
    "    auto_offset_reset='earliest',\n",
    "     # Stop iteration if no message after 0.5sec\n",
    "    consumer_timeout_ms=500)\n",
    "tp = TopicPartition(topic,0)\n",
    "consumer.assign([tp])\n",
    "\n",
    "# Go to the beginning of the queue\n",
    "consumer.seek(tp, 0)\n",
    "\n",
    "for message in consumer:\n",
    "    # message value and key are raw bytes -- decode if necessary!\n",
    "    # e.g., for unicode: `message.value.decode('utf-8')`\n",
    "    print(f\"{message.topic}:{message.partition}:{message.offset}: key={message.key} value={message.value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clearing Jupyter Notebook Output\n",
    "\n",
    "Since the server writes a log line to output for every request, it's possible to **write so much output that the notebook hangs**. Therefore, it's best to clear the output every few messages.\n",
    "\n",
    "You can clear the output using Python. It's advised to clear the output at least every 500 messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This line will be visible.\n",
      "This is visible too!\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "print(\"This line will be cleared.\")\n",
    "print(\"This line will be cleared too.\")\n",
    "clear_output()\n",
    "print(\"This line will be visible.\")\n",
    "print(\"This is visible too!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Endpoint API\n",
    "\n",
    "> **Task:** Write a server that listens for `POST` requests to the url `/clicks`, reads the body of the request as `json`, and sends sends that body to the `clicks` topic on Kafka.\n",
    "\n",
    "tips:\n",
    "\n",
    "* Use KafkaProducer for writing to Kafka.\n",
    "* Remember data sent to Kafka needs to be in binary format.\n",
    "  * Turn Python dictionaries into a json string using `string = json.dumps(python_object)`\n",
    "  * Turn the json string into binary format using `string.encode('utf-8')`\n",
    "* Use Flask for the webserver.\n",
    "  * Get the request body with `request.json`.\n",
    "  * In order to respond to POST requests, add `methods=['POST']` to the `app.route()` of a function.\n",
    "  * The return value of the view functions get processed by [`make_response`](https://flask.palletsprojects.com/en/1.1.x/api/#flask.Flask.make_response). Return a tuple with a response body and the status code.\n",
    "    * If the request is malformed, respond with the HTTP status code `400` and include in the body of the response a message explaining the issue.\n",
    "    * If writing the rating to Kafka succeeds, respond with the HTTP status code `200`.\n",
    "* Clear the Jupyter notebook output every X requests using `clear_output()`.\n",
    "\n",
    "\n",
    "Use `1b-fake-website.ipynb` to simulate click data. You can use the scripts in `debug.ipynb` to read from Kafka topics to see if the messages are pushed correctly.\n",
    "\n",
    "The [postman app](https://www.postman.com/downloads/) is a useful GUI tool to create HTTP calls for testing. You can also use curl to test the api from the cli:\n",
    "\n",
    "```bash\n",
    "curl --header \"Content-Type: application/json\" \\\n",
    "     --request POST \\\n",
    "     --data '{\"visitor_platform\": \"mobile\",\"ts_ingest\": 1515819844345,\"article_title\": \"Cercanías San Sebastián\",\"visitor_country\": \"BE\",\"visitor_page_timer\": 0,\"visitor_os\": \"ios\",\"article\": \"https://en.wikipedia.org/wiki/Cercan%C3%ADas_San_Sebasti%C3%A1n\",\"visitor_page_height\": 0,\"visitor_browser\": \"unknown\"}' \\\n",
    "     http://localhost:5000/clicks\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__' (lazy loading)\n",
      " * Environment: production\n",
      "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
      "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on all addresses.\n",
      "   WARNING: This is a development server. Do not use it in a production deployment.\n",
      " * Running on http://172.24.0.3:5000/ (Press CTRL+C to quit)\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import datetime\n",
    "import uuid\n",
    "import re\n",
    "import os\n",
    "from flask import Flask, request, Response, send_file, send_from_directory\n",
    "from kafka import KafkaProducer\n",
    "from IPython.display import clear_output\n",
    "\n",
    "# Create a Kafka producer. The server is available at localhost:9092\n",
    "producer = KafkaProducer(bootstrap_servers=['localhost:9092'])\n",
    "\n",
    "# Variable to count how many lines the server wrote to stdout\n",
    "i = 0\n",
    "\n",
    "# Create a new webserver\n",
    "app = Flask(__name__, static_url_path='')\n",
    "\n",
    "# Handle POST requests to http://localhost/clicks\n",
    "@app.route('/clicks', methods=['POST'])\n",
    "def extranm():\n",
    "    # Clear the output after every 1000 requests\n",
    "    global i\n",
    "    if i > 1000:\n",
    "        clear_output()\n",
    "        i = 0\n",
    "    i = i+1\n",
    "    \n",
    "    # Get the json body of the POST request as a Python dictionary\n",
    "    rjson = request.json\n",
    "    \n",
    "    # If parsing the json failed, return a 400 HTTP error code\n",
    "    if not rjson:\n",
    "        return (\n",
    "            json.dumps({'success': False, 'message': 'could not decode json'}),\n",
    "            400,\n",
    "            {'ContentType':'application/json'}\n",
    "        )\n",
    "\n",
    "    # If parsing succeeded, try for 5 seconds to send the event to Kafka\n",
    "    producer.send('clicks', json.dumps(rjson).encode('utf-8')).get(timeout=5)\n",
    "\n",
    "    # If sending succeeded, respond to the client that all is wel\n",
    "    return (\n",
    "        json.dumps({'success': True}),\n",
    "        200,\n",
    "        {'ContentType':'application/json'}\n",
    "    )\n",
    "\n",
    "# Run the webserver\n",
    "app.run(host='0.0.0.0')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
